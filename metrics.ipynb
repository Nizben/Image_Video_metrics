{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorchvideo\n",
        "!pip install scikit-image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjhBckjlZ2u9",
        "outputId": "387c9d6b-5c32-416b-9da9-4b4fa878d10d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorchvideo in /usr/local/lib/python3.11/dist-packages (0.1.5)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (0.1.5.post20221221)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (14.1.0)\n",
            "Requirement already satisfied: parameterized in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (0.1.10)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (1.26.4)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (2.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (11.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath->pytorchvideo) (4.12.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath->pytorchvideo) (3.1.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "snA_G9jNZWzw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import linalg\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from pytorchvideo.models.hub import i3d_r50\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoFeatureExtractor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = i3d_r50(pretrained=True)\n",
        "        self.model.eval()\n",
        "\n",
        "    def forward(self, videos):\n",
        "        # videos: (B, C, T, H, W), pixel values in [0, 255]\n",
        "        videos = videos / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "        # Resize spatial dimensions using Option 1:\n",
        "        B, C, T, H, W = videos.shape\n",
        "        videos = videos.view(B * T, C, H, W)\n",
        "        videos = F.interpolate(videos, size=(224, 224), mode='bilinear')\n",
        "        videos = videos.view(B, T, C, 224, 224).permute(0, 2, 1, 3, 4)\n",
        "\n",
        "        features = self.model(videos)  # Output: (B, 2048)\n",
        "        return features\n",
        "\n",
        "def calculate_fid(real_features, generated_features, eps=1e-6):\n",
        "    mu1, sigma1 = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
        "    mu2, sigma2 = np.mean(generated_features, axis=0), np.cov(generated_features, rowvar=False)\n",
        "\n",
        "    sigma1 += eps * np.eye(sigma1.shape[0])\n",
        "    sigma2 += eps * np.eye(sigma2.shape[0])\n",
        "\n",
        "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    covmean = covmean.real\n",
        "\n",
        "    fid = np.sum((mu1 - mu2) ** 2) + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
        "    return fid\n",
        "\n",
        "def get_features(dataloader, model, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Extracting Features\"):\n",
        "            batch = batch.to(device)\n",
        "            feats = model(batch).cpu().numpy()\n",
        "            features.append(feats)\n",
        "    return np.concatenate(features, axis=0)"
      ],
      "metadata": {
        "id": "M_jQJfBzZ4G8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device settings\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = VideoFeatureExtractor().to(device)\n",
        "\n",
        "# Number of videos, channels, frames, height, width\n",
        "N, C, T, H, W = 100, 3, 16, 224, 224\n",
        "\n",
        "# Generate \"real\" videos using random integers in the range [0, 255]\n",
        "real_videos = torch.randint(0, 256, (N, C, T, H, W), dtype=torch.uint8).float()\n",
        "\n",
        "# Generate \"generated\" videos: add a small bias to simulate differences\n",
        "# For instance, add a bias of 10 to the pixel values and clamp them to [0, 255]\n",
        "gen_videos = real_videos + 10.0\n",
        "gen_videos = gen_videos.clamp(0, 255)\n",
        "\n",
        "# Create DataLoaders\n",
        "real_loader = DataLoader(real_videos, batch_size=16)\n",
        "gen_loader = DataLoader(gen_videos, batch_size=16)\n",
        "\n",
        "# Extract features\n",
        "real_feats = get_features(real_loader, model, device)\n",
        "gen_feats = get_features(gen_loader, model, device)\n",
        "\n",
        "# Calculate FID\n",
        "fid_score = calculate_fid(real_feats, gen_feats)\n",
        "print(f\"FID: {fid_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta9T43OPZ_CH",
        "outputId": "9c3fc65b-a028-4a90-b5ed-f3879821a129"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 7/7 [00:07<00:00,  1.14s/it]\n",
            "Extracting Features: 100%|██████████| 7/7 [00:07<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 0.0737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import structural_similarity\n",
        "\n",
        "def calculate_psnr(video1, video2):\n",
        "    # Inputs: (N, C, T, H, W) in [0, 255]\n",
        "    mse = np.mean((video1 - video2)**2, axis=(1, 2, 3, 4))\n",
        "    psnr = 20 * np.log10(255.0 / np.sqrt(mse))\n",
        "    return np.mean(psnr)\n",
        "\n",
        "def calculate_ssim(video1, video2):\n",
        "    # Inputs: (N, T, H, W, C) in [0, 255]\n",
        "    ssim_scores = []\n",
        "    for vid1, vid2 in zip(video1, video2):\n",
        "        vid1 = vid1.astype(np.float32)\n",
        "        vid2 = vid2.astype(np.float32)\n",
        "        ssim_batch = [structural_similarity(f1, f2, channel_axis=-1, data_range=255) for f1, f2 in zip(vid1, vid2)]\n",
        "        ssim_scores.append(np.mean(ssim_batch))\n",
        "    return np.mean(ssim_scores)\n",
        "\n",
        "# Example Usage\n",
        "real_video = np.random.randint(0, 256, (10, 16, 224, 224, 3), dtype=np.uint8)  # (N, T, H, W, C)\n",
        "gen_video = np.random.randint(0, 256, (10, 16, 224, 224, 3), dtype=np.uint8)\n",
        "\n",
        "psnr = calculate_psnr(real_video, gen_video)\n",
        "ssim = calculate_ssim(real_video, gen_video)\n",
        "print(f\"PSNR: {psnr:.3f} dB, SSIM: {ssim:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAksbsbTaNa7",
        "outputId": "c1663ab7-c7c1-4c1b-f603-3057a2cf3f5b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 27.897 dB, SSIM: 0.0053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ok8tcMW2e-Mr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}